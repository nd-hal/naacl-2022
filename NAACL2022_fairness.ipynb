{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtgbrM76oD9s"
   },
   "source": [
    "# ACL 2022 Submission: Fairness Calculations\n",
    "\n",
    "The input required here is the merged prediction files, and the gold standard data with the relevant demographic information.\n",
    "\n",
    "Output is a spreadsheet with calculated intersectional DI scores.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First the following upgrades are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "75mLLOyW_lBE",
    "outputId": "8e7ad4be-61a8-4e88-bab8-465b34ce3473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/2f/0e/3b74e8f7c908082793adafb02753477f653ccd7e189f3ba070757d2d0e65/pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.0\n",
      "    Uninstalling pandas-2.1.0:\n",
      "      Successfully uninstalled pandas-2.1.0\n",
      "Successfully installed pandas-2.1.1\n",
      "Requirement already satisfied: openpyxl in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/lalor/miniconda3/envs/naacl2022/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas\n",
    "!pip install --upgrade openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TO6IMa8vE5aW"
   },
   "source": [
    "## Restart runtime after executing the above cell to get the latest version of pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-meESHofN0uc"
   },
   "source": [
    "# Psychometric and FIPI Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljhNFRHEytvn",
    "outputId": "74e299cb-6ae3-46ea-ab4b-92d4aeaf7b87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "2023-10-25 15:43:02.052004: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-25 15:43:03.260234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Columns (25,26,27,36,37,38,41,53,54,55,56,57,58,59,60,61,62,126,127,128,130,131,133,134,136) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "12619    NaN\n",
      "12620    1.0\n",
      "12621    1.0\n",
      "12622    0.0\n",
      "12623    1.0\n",
      "Name: gender, Length: 83077, dtype: float64\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "12618    0.0\n",
      "12620    1.0\n",
      "12621    1.0\n",
      "12622    0.0\n",
      "12623    1.0\n",
      "Name: gender, Length: 44401, dtype: float64\n",
      "42009\n",
      "['Age_Gender', 'Age_Gender_Race', 'Age_Gender_Race_Education', 'Age_Gender_Race_Income', 'Age_Gender_Education', 'Age_Gender_Education_Income', 'Age_Gender_Income', 'Age_Race', 'Age_Race_Education', 'Age_Race_Education_Income', 'Age_Race_Income', 'Age_Education', 'Age_Education_Income', 'Age_Income', 'Gender_Race', 'Gender_Race_Education', 'Gender_Race_Education_Income', 'Gender_Race_Income', 'Gender_Education', 'Gender_Education_Income', 'Gender_Income', 'Race_Education', 'Race_Education_Income', 'Race_Income', 'Education_Income', 'Age_Gender_Race_Education_Income']\n"
     ]
    }
   ],
   "source": [
    "# load libraries and data\n",
    "# to replicate on google colab just drag and drop relevant files into the directory (they do not persist)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "\n",
    "from aif360.sklearn.metrics import disparate_impact_ratio\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# need this for psychometric data, the other ones have demographics in the files\n",
    "test_data_psych = pd.read_excel(\"PsychometricData.xlsx\", skiprows=lambda x: x in [1], header=0)\n",
    "test_data_fipi = pd.read_csv(\"fipi.csv\")\n",
    "HS_train = pd.read_csv(\"trainHS.csv\")\n",
    "HS_valid = pd.read_csv(\"validHS.csv\")\n",
    "HS_test = pd.read_csv(\"testHS.csv\")\n",
    "frames = [HS_train, HS_valid, HS_test]\n",
    "test_data_HS = pd.concat(frames)\n",
    "\n",
    "test_data_psych = test_data_psych[[\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\n",
    "            \"Text_TrustPhys\",\"Label_SubjectiveLit\",\"Label_TrustPhys\",\n",
    "            \"Label_Anxiety\",\"Label_Numeracy\",\"D1\",\n",
    "            \"D2\",\"D3\",\"D4\",\"D5\",\"D6\",\n",
    "            ]]\n",
    "\n",
    "test_data_fipi = test_data_fipi[[\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\n",
    "            \"Text_TrustPhys\",\"Label_SubjectiveLit\",\"Label_TrustPhys\",\n",
    "            \"Label_Anxiety\",\"Label_Numeracy\",\"D1\",\n",
    "            \"D2\",\"D3\",\"D4\",\"D5\",\"D6\",\n",
    "            ]]\n",
    "\n",
    "test_data_HS = test_data_HS[[\"text\", \"gender\", \"age\",\"country\",\"ethnicity\",\"label\"]]\n",
    "\n",
    "\n",
    "test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_fipi[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n",
    "test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']] = test_data_psych[['D1', 'D2', 'D3', 'D4', 'D5']].apply(pd.to_numeric, errors='coerce')\n",
    "test_data_HS[[\"gender\", \"age\",\"ethnicity\",\"label\"]] = test_data_HS[[\"gender\", \"age\",\"ethnicity\",\"label\"]].apply(pd.to_numeric, errors='coerce')\n",
    "print(test_data_HS.gender)\n",
    "test_data_psych.dropna(subset=['D1', 'D2', 'D3', 'D4', 'D5'], inplace=True)\n",
    "test_data_fipi.dropna(subset=['D1', 'D2', 'D3', 'D4', 'D5'], inplace=True)\n",
    "test_data_HS.dropna(subset=[\"gender\", \"age\",\"ethnicity\",\"label\"], inplace=True)\n",
    "print(test_data_HS.gender)\n",
    "\n",
    "test_data_HS.rename(\n",
    "    columns={\n",
    "        \"gender\":\"Gender_bin\",\n",
    "        \"age\":\"Age_bin\",\n",
    "        \"ethnicity\":\"Race_bin\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "test_data_HS = test_data_HS[~test_data_HS.text.str.contains(\"user user user\")]\n",
    "print(len(test_data_HS.text))\n",
    "\"\"\"\n",
    "### Demographic binarization assumptions\n",
    "\n",
    "- D1 (Age): Over/under 55\n",
    "- D2 (Gender): already binarized\n",
    "- D3 (Race): White/non-White\n",
    "- D4 (Education): College grad or higher yes/no\n",
    "- D5 (Income): $55k+ yes/no \n",
    "\"\"\"\n",
    "\n",
    "# first binarize all of our columns.\n",
    "test_data_fipi[\"Age_bin\"] = (test_data_fipi[\"D1\"] <= 38).astype(int)\n",
    "test_data_fipi[\"Gender_bin\"] = (test_data_fipi[\"D2\"] == 1).astype(int)\n",
    "test_data_fipi[\"Race_bin\"] = (test_data_fipi[\"D3\"] == 1).astype(int)\n",
    "test_data_fipi[\"Education_bin\"] = (test_data_fipi[\"D4\"] >= 5).astype(int)\n",
    "test_data_fipi[\"Income_bin\"] = (test_data_fipi[\"D5\"] >= 4).astype(int)\n",
    "\n",
    "test_data_psych[\"Age_bin\"] = (test_data_psych[\"D1\"] <= 38).astype(int)\n",
    "test_data_psych[\"Gender_bin\"] = (test_data_psych[\"D2\"] == 1).astype(int)\n",
    "test_data_psych[\"Race_bin\"] = (test_data_psych[\"D3\"] == 1).astype(int)\n",
    "test_data_psych[\"Education_bin\"] = (test_data_psych[\"D4\"] >= 5).astype(int)\n",
    "test_data_psych[\"Income_bin\"] = (test_data_psych[\"D5\"] >= 4).astype(int)\n",
    "\n",
    "# I should be able to calculate all intersections programmatically. \n",
    "\n",
    "column_names = [\"Age_bin\", \"Gender_bin\", \"Race_bin\", \"Education_bin\", \"Income_bin\"]\n",
    "\n",
    "combinations = []\n",
    "# two-way \n",
    "for aa in range(len(column_names)):\n",
    "  a = column_names[aa]\n",
    "  for bb in range(aa + 1, len(column_names)):\n",
    "    b = column_names[bb]\n",
    "    if a == b:\n",
    "      continue \n",
    "    combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0])\n",
    "    for cc in range(bb + 1, len(column_names)):\n",
    "      c = column_names[cc]\n",
    "      if a == b or a == c or b == c:\n",
    "        continue \n",
    "      combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0] + \"_\" + c.split(\"_\")[0])\n",
    "      for dd in range(cc + 1, len(column_names)):\n",
    "        d = column_names[dd]  \n",
    "        if a == b or a == c or a == d or b == c or b == d or c == d:\n",
    "          continue \n",
    "        combinations.append(a.split(\"_\")[0] + \"_\" + b.split(\"_\")[0] + \"_\" + c.split(\"_\")[0] + \"_\" + d.split(\"_\")[0])\n",
    "      \n",
    "combinations.append(\"Age_Gender_Race_Education_Income\")\n",
    "\n",
    "print(combinations)\n",
    "\n",
    "# this will be a fraction: what percentage of categories is someone in the privileged class? \n",
    "\n",
    "\n",
    "for comb in combinations:\n",
    "  columns = [a + \"_bin\" for a in comb.split(\"_\")]\n",
    "  test_data_psych[comb] = 0\n",
    "  for i in range(len(columns)):\n",
    "    test_data_psych[comb] += test_data_psych[columns[i]].astype(float)\n",
    "  test_data_psych[comb] = test_data_psych[comb] / len(columns) \n",
    "\n",
    "  test_data_fipi[comb] = 0\n",
    "  for i in range(len(columns)):\n",
    "    test_data_fipi[comb] += test_data_fipi[columns[i]].astype(float)\n",
    "  test_data_fipi[comb] = test_data_fipi[comb] / len(columns) \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NJYava8MjS-W"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4SVjW-J_qPH8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generatePlots_v3(basefile, modelTask, textCol, full_N=False, gold_ratio=False):\n",
    "    frames = []\n",
    "\n",
    "    fname = basefile\n",
    "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\") \n",
    "    df = bert_preds\n",
    "\n",
    "    df[\"s1\"] = df[\"sentence\"]\n",
    "    if \"FIPI\" in basefile:\n",
    "      test_data = test_data_fipi\n",
    "    else:\n",
    "      test_data = test_data_psych\n",
    "    test_data[\"s1\"] = test_data[textCol]\n",
    "    D = df.merge(test_data, on=\"s1\", how=\"inner\")\n",
    "    print(\"start: \" + str(len(df[\"s1\"])))\n",
    "    print(\"merge: \" + str(len(D[\"s1\"])))\n",
    "\n",
    "    try:\n",
    "      D[\"probs\"] = D[\"preds\"]\n",
    "    except:\n",
    "      D[\"probs\"] = D[\"pred\"]\n",
    "\n",
    "    # For continuous, we'll use the stated label\n",
    "    # calculate median and use that as cutoff instead of 0.5 \n",
    "    if \"Continuous\" in basefile:\n",
    "      labelColumn = textCol.replace(\"Text\", \"Label\")\n",
    "      median_val = statistics.median(D[labelColumn])\n",
    "      try:\n",
    "        print(D[\"label\"])\n",
    "      except:\n",
    "        D[\"label\"] = D[labelColumn]\n",
    "      D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
    "      D[\"label_binarized\"] = D[\"label\"].apply(lambda x: 0 if x < median_val else 1)\n",
    "      print(median_val)\n",
    "    else:\n",
    "      D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < 0.5 else 1)\n",
    "      D[\"label_binarized\"] = D[\"label\"]\n",
    "\n",
    "    D2 = D\n",
    "\n",
    "    demogColumns = [\n",
    "                    \"Age_bin\", \"Gender_bin\", \"Race_bin\",\n",
    "        \"Education_bin\", \"Income_bin\", \"Age_Gender\", \"Age_Gender_Race\",\n",
    "        \"Age_Gender_Race_Education\", \"Age_Gender_Race_Income\",\n",
    "        \"Age_Gender_Education\", \"Age_Gender_Education_Income\",\n",
    "        \"Age_Gender_Income\", \"Age_Race\", \"Age_Race_Education\",\n",
    "        \"Age_Race_Education_Income\", \"Age_Race_Income\", \"Age_Education\",\n",
    "        \"Age_Education_Income\", \"Age_Income\", \"Gender_Race\",\n",
    "        \"Gender_Race_Education\", \"Gender_Race_Education_Income\",\n",
    "        \"Gender_Race_Income\", \"Gender_Education\", \"Gender_Education_Income\",\n",
    "        \"Gender_Income\", \"Race_Education\", \"Race_Education_Income\",\n",
    "        \"Race_Income\", \"Education_Income\", \"Age_Gender_Race_Education_Income\"\n",
    "    ]\n",
    "    DIs = []\n",
    "    demog_trues = []\n",
    "    FVs = []\n",
    "\n",
    "    # laplace smoothing to account for zeros\n",
    "    for dc in demogColumns:\n",
    "      \n",
    "      positive_predictions = D2[\"probs_binarized\"]==1\n",
    "      positive_gold = D2[\"label_binarized\"]==1\n",
    "      protected = D2[dc]==0\n",
    "      privileged = D2[dc] == 1\n",
    "      N = 2\n",
    "      alpha = 1\n",
    "\n",
    "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
    "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
    "\n",
    "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
    "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
    "\n",
    "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
    "\n",
    "\n",
    "      try:\n",
    "        DI = DI_numerator / DI_denominator\n",
    "        ytrue = ytrue_numerator / ytrue_denominator\n",
    "        FV = np.abs(DI_numerator - ypred_global)\n",
    "      except:\n",
    "        DI=0\n",
    "        ytrue=0\n",
    "        FV=0\n",
    "      \n",
    "      if gold_ratio: \n",
    "          DI = DI / ytrue\n",
    "      \n",
    "      DIs.append(DI) \n",
    "      FVs.append(FV)\n",
    "      demog_trues.append((dc, ytrue))\n",
    "\n",
    "    # auc from sklearn\n",
    "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # other metrics: MSE, pearson, F1\n",
    "    mse = mean_squared_error(D2[\"label\"], D2[\"probs\"])\n",
    "    pearsonscore, prob = pearsonr(D2[\"label\"], D2[\"probs\"])\n",
    "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
    "\n",
    "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
    "\n",
    "\n",
    "\n",
    "def get_results(full_N, gold_ratio, models):\n",
    "    DIs, aucs, xaucs = [], [], []\n",
    "    task = []\n",
    "    dc_tracker = []\n",
    "    l = []\n",
    "    results = []\n",
    "    demog_trues = []\n",
    "\n",
    "    for basefname in models:\n",
    "      for i in range(len(modelTasks)):\n",
    "        m = modelTasks[i]\n",
    "        l.append(m) \n",
    "        print(i, textCols)\n",
    "        colname = textCols[i]\n",
    "        print(basefname, m, colname)\n",
    "        if m.lower() not in basefname.lower():\n",
    "          if 'FIPI' in basefname and m.lower() ==\"subjectivelit\":\n",
    "            m = \"SubjectiveLit\"\n",
    "          else:\n",
    "            continue\n",
    "        outs, dt = generatePlots_v3(basefname, m, colname, full_N, gold_ratio)\n",
    "        if len(demog_trues) == 0:\n",
    "          demog_trues.extend(dt)\n",
    "        modelname = basefname.split(\"/\")[1]\n",
    "        results.append([modelname, m] + outs)\n",
    "\n",
    "    colnames = [\"model\", \n",
    "              \"DV\", \n",
    "              \"MSE\", \"Pearson R\", \"F1\",\n",
    "              \"AUC\", \n",
    "        \"DI_Age_bin\", \"DI_Gender_bin\", \"DI_Race_bin\",\n",
    "        \"DI_Education_bin\", \"DI_Income_bin\", \"DI_Age_Gender\", \"DI_Age_Gender_Race\",\n",
    "        \"DI_Age_Gender_Race_Education\", \"DI_Age_Gender_Race_Income\",\n",
    "        \"DI_Age_Gender_Education\", \"DI_Age_Gender_Education_Income\",\n",
    "        \"DI_Age_Gender_Income\", \"DI_Age_Race\", \"DI_Age_Race_Education\",\n",
    "        \"DI_Age_Race_Education_Income\", \"DI_Age_Race_Income\", \"DI_Age_Education\",\n",
    "        \"DI_Age_Education_Income\", \"DI_Age_Income\", \"DI_Gender_Race\",\n",
    "        \"DI_Gender_Race_Education\", \"DI_Gender_Race_Education_Income\",\n",
    "        \"DI_Gender_Race_Income\", \"DI_Gender_Education\", \"DI_Gender_Education_Income\",\n",
    "        \"DI_Gender_Income\", \"DI_Race_Education\", \"DI_Race_Education_Income\",\n",
    "        \"DI_Race_Income\", \"DI_Education_Income\", \"DI_Age_Gender_Race_Education_Income\",\n",
    "        \"FV_Age_bin\", \"FV_Gender_bin\", \"FV_Race_bin\",\n",
    "        \"FV_Education_bin\", \"FV_Income_bin\", \"FV_Age_Gender\", \"FV_Age_Gender_Race\",\n",
    "        \"FV_Age_Gender_Race_Education\", \"FV_Age_Gender_Race_Income\",\n",
    "        \"FV_Age_Gender_Education\", \"FV_Age_Gender_Education_Income\",\n",
    "        \"FV_Age_Gender_Income\", \"FV_Age_Race\", \"FV_Age_Race_Education\",\n",
    "        \"FV_Age_Race_Education_Income\", \"FV_Age_Race_Income\", \"FV_Age_Education\",\n",
    "        \"FV_Age_Education_Income\", \"FV_Age_Income\", \"FV_Gender_Race\",\n",
    "        \"FV_Gender_Race_Education\", \"FV_Gender_Race_Education_Income\",\n",
    "        \"FV_Gender_Race_Income\", \"FV_Gender_Education\", \"FV_Gender_Education_Income\",\n",
    "        \"FV_Gender_Income\", \"FV_Race_Education\", \"FV_Race_Education_Income\",\n",
    "        \"FV_Race_Income\", \"FV_Education_Income\", \"FV_Age_Gender_Race_Education_Income\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results) \n",
    "    df.columns = colnames\n",
    "\n",
    "    return df, demog_trues\n",
    "\n",
    "def calculate_fairness(infile, outfile, weighted=False, unionYN=False):\n",
    "\n",
    "  models = [infile]\n",
    "\n",
    "  output, demogs = get_results(\n",
    "    unionYN,\n",
    "    weighted, \n",
    "    models\n",
    "  )\n",
    "\n",
    "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
    "  wordlists = wordlists.split(\".\")[0]\n",
    "  output[\"model\"] = outfile\n",
    "  output[\"adjustedDI\"] = weighted\n",
    "  output[\"debiasing\"] = debiasing\n",
    "  output[\"wordlists\"] = wordlists\n",
    "  output[\"fullN\"] = unionYN\n",
    "\n",
    "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
    "  demog_df[\"model\"] = outfile\n",
    "  demog_df[\"ratio\"] = weighted\n",
    "\n",
    "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwUjw75w-N3X",
    "outputId": "bede23aa-5c2e-4b1e-89ac-d5ad169c3a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8302\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8302\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8301\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8301\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "0       0.333300\n",
      "1       0.285700\n",
      "2       0.476200\n",
      "3       0.928571\n",
      "4       0.476200\n",
      "          ...   \n",
      "8361    0.190476\n",
      "8362    0.142857\n",
      "8363    0.190476\n",
      "8364    0.785700\n",
      "8365    0.666700\n",
      "Name: label, Length: 8366, dtype: float64\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8302\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8302\n",
      "0.52381\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8366\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8301\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "start: 8395\n",
      "merge: 8301\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Anxiety_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8396\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8396\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8392\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8392\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "0       0.571400\n",
      "1       0.714300\n",
      "2       1.000000\n",
      "3       0.785714\n",
      "4       0.785700\n",
      "          ...   \n",
      "8445    0.428571\n",
      "8446    0.714286\n",
      "8447    1.000000\n",
      "8448    0.214300\n",
      "8449    0.571400\n",
      "Name: label, Length: 8450, dtype: float64\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8397\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8397\n",
      "0.714286\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8450\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8392\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "start: 8484\n",
      "merge: 8392\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_Numeracy_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8408\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8408\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8407\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8407\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "0       0.766700\n",
      "1       0.883300\n",
      "2       0.855600\n",
      "3       0.861111\n",
      "4       0.872200\n",
      "          ...   \n",
      "8463    0.916667\n",
      "8464    0.916667\n",
      "8465    0.916667\n",
      "8466    0.600000\n",
      "8467    0.916700\n",
      "Name: label, Length: 8468, dtype: float64\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8409\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8409\n",
      "0.838889\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8468\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8407\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 8502\n",
      "merge: 8407\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_SubjectiveLit_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8403\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8403\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8402\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PT_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8402\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0       0.68\n",
      "1       0.76\n",
      "2       0.80\n",
      "3       0.68\n",
      "4       0.80\n",
      "        ... \n",
      "8459    1.00\n",
      "8460    0.52\n",
      "8461    0.72\n",
      "8462    0.80\n",
      "8463    0.80\n",
      "Name: label, Length: 8464, dtype: float64\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8404\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Continuous_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8404\n",
      "0.76\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_BERT_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_RoBERTa_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8464\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8402\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "3 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/Psychometric_TrustPhys_Binary_PTD_CNN_test.csv TrustPhys Text_TrustPhys\n",
      "start: 8498\n",
      "merge: 8402\n",
      "0 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/FIPI_Extraverted_Continuous_PT_BERT_test.csv Anxiety Text_Anxiety\n",
      "1 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/FIPI_Extraverted_Continuous_PT_BERT_test.csv Numeracy Text_Numeracy\n",
      "2 ['Text_Anxiety', 'Text_Numeracy', 'Text_SubjectiveLit', 'Text_TrustPhys']\n",
      "merged/FIPI_Extraverted_Continuous_PT_BERT_test.csv SubjectiveLit Text_SubjectiveLit\n",
      "start: 7475\n",
      "merge: 1\n",
      "0    0.285714\n",
      "Name: label, dtype: float64\n",
      "0.916667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No positive samples in y_true, true positive value should be meaningless\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_117015/1395278473.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mmm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m               \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"merged/{m}_{t}_{d}_{mm}_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m               \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m               \u001b[0mcalculate_fairness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m               \u001b[0moutname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0mcalculate_fairness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_117015/3299614970.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(infile, outfile, weighted, unionYN)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_fairness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munionYN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m   output, demogs = get_results(\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0munionYN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_117015/3299614970.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(full_N, gold_ratio, models)\u001b[0m\n\u001b[1;32m    122\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m'FIPI'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbasefname\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"subjectivelit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SubjectiveLit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneratePlots_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemog_trues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           \u001b[0mdemog_trues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mmodelname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasefname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_117015/3299614970.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(basefile, modelTask, textCol, full_N, gold_ratio)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# other metrics: MSE, pearson, F1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mpearsonscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mf1score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"probs_binarized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpearsonscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDIs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFVs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemog_trues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/naacl2022/lib/python3.10/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(x, y, alternative, method)\u001b[0m\n\u001b[1;32m   4764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4765\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have length at least 2.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4771\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "modelTasks = [\"Anxiety\", \"Numeracy\", \"SubjectiveLit\", \"TrustPhys\"]\n",
    "\n",
    "textCols = [\"Text_Anxiety\",\"Text_Numeracy\",\"Text_SubjectiveLit\",\"Text_TrustPhys\"]\n",
    "\n",
    "labelCols = [\"Label_Anxiety\",\"Label_Numeracy\",\"Label_SubjectiveLit\",\"Label_TrustPhys\"]\n",
    "taskNames = [\n",
    "            'Psychometric_Anxiety',\n",
    "            'Psychometric_Numeracy',\n",
    "            'Psychometric_SubjectiveLit',\n",
    "            'Psychometric_TrustPhys',\n",
    "            'FIPI_Extraverted',\n",
    "            'FIPI_Stable'\n",
    "]\n",
    "\n",
    "debiasing = [\n",
    "    \"PT\",\n",
    "    \"PTD\"\n",
    "    #\"PTDCDA\",\n",
    "    #\"PTDDropout\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"Continuous\",\n",
    "    \"Binary\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"BERT\",\n",
    "    \"RoBERTa\",\n",
    "    \"CNN\"\n",
    "]\n",
    "\n",
    "\n",
    "for m in taskNames:\n",
    "    for d in debiasing:\n",
    "        for t in tasks:\n",
    "          for mm in models:\n",
    "              fname = f\"merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
    "              outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
    "              calculate_fairness(fname, outname, weighted=False, unionYN=False)\n",
    "              outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
    "              calculate_fairness(fname, outname, weighted=True, unionYN=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JrHNWrcN5FL"
   },
   "source": [
    "# Ask a Patient Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZ0fVsybNV7V"
   },
   "outputs": [],
   "source": [
    "def generatePlots_AAP(basefile, full_N=False, gold_ratio=False):\n",
    "    frames = []\n",
    "\n",
    "    fname = basefile\n",
    "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\") \n",
    "    D = bert_preds\n",
    "    df = D\n",
    "\n",
    "    if \"CNN\" in fname:\n",
    "      bertfile = fname.replace(\"CNN\", \"BERT\")\n",
    "      test_data = pd.read_csv(bertfile, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
    "      D = df.merge(test_data, on=\"sentence\", how=\"inner\")\n",
    "      print(\"start: \" + str(len(df[\"sentence\"])))\n",
    "      print(\"merge: \" + str(len(D[\"sentence\"])))\n",
    "      try:\n",
    "        D[\"probs\"] = D[\"preds\"]\n",
    "      except:\n",
    "        D[\"probs\"] = D[\"pred\"]\n",
    "    else:\n",
    "      try:\n",
    "        D[\"probs\"] = D[\"preds\"]\n",
    "      except:\n",
    "        D[\"probs\"] = D[\"pred\"]\n",
    "\n",
    "    # For continuous, we'll use the stated label\n",
    "    # calculate median and use that as cutoff instead of 0.5 \n",
    "    #median_val = 0.5\n",
    "    median_val = statistics.median(D[\"label\"])\n",
    "\n",
    "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
    "    D[\"label_binarized\"] = D[\"label\"].apply(lambda x: 0 if x < median_val else 1)\n",
    "    print(median_val)\n",
    "    D2 = D.dropna()\n",
    "\n",
    "    demogColumns = [\n",
    "                    \"Age\", \"Gender\", \"Age_Gender\"\n",
    "    ]\n",
    "    DIs = []\n",
    "    FVs=[]\n",
    "    demog_trues = []\n",
    "    D2[\"Age\"] = (D2[\"x2\"] <= 56).astype(int)\n",
    "    D2[\"Gender\"] = (D2[\"x1\"] == \"M\").astype(int)\n",
    "    D2[\"Age_Gender\"] = (D2[\"Age\"].astype(int) + D2[\"Gender\"].astype(int)) / 2\n",
    "    \n",
    "\n",
    "    for dc in demogColumns:\n",
    "      \n",
    "      positive_predictions = D2[\"probs_binarized\"]==1\n",
    "      positive_gold = D2[\"label_binarized\"]==1\n",
    "      protected = D2[dc]==0\n",
    "      privileged = D2[dc] == 1\n",
    "      N = 2\n",
    "      alpha = 1\n",
    "      \n",
    "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
    "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
    "\n",
    "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
    "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
    "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
    "\n",
    "      DI = DI_numerator / DI_denominator\n",
    "      ytrue = ytrue_numerator / ytrue_denominator\n",
    "      FV = np.abs(DI_numerator - ypred_global)\n",
    "      \n",
    "      if gold_ratio: \n",
    "          DI = DI / ytrue\n",
    "      print(dc)\n",
    "\n",
    "      \n",
    "      DIs.append(DI) \n",
    "      FVs.append(FV)\n",
    "      demog_trues.append((dc, ytrue))\n",
    "\n",
    "    # auc from sklearn\n",
    "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    mse = mean_squared_error(D2[\"label\"], D2[\"probs\"])\n",
    "    pearsonscore, prob = pearsonr(D2[\"label\"], D2[\"probs\"])\n",
    "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
    "\n",
    "    return [mse, pearsonscore, f1score, auc] + DIs+FVs, demog_trues\n",
    "\n",
    "\n",
    "def get_results_AAP(full_N, gold_ratio, models):\n",
    "    DIs, aucs, xaucs = [], [], []\n",
    "    task = []\n",
    "    dc_tracker = []\n",
    "    l = []\n",
    "    results = []\n",
    "    demog_trues = []\n",
    "\n",
    "    for basefname in models:\n",
    "        outs, dt = generatePlots_AAP(basefname, full_N, gold_ratio)\n",
    "        if len(demog_trues) == 0:\n",
    "          demog_trues.extend(dt)\n",
    "        modelname = basefname.split(\"/\")[1]\n",
    "        results.append([modelname, m] + outs)\n",
    "\n",
    "    colnames = [\"model\", \n",
    "              \"DV\", \n",
    "              \"MSE\", \"Pearson R\", \"F1\",\n",
    "              \"AUC\", \n",
    "        \"DI_Age\", \"DI_Gender\", \"DI_Age_Gender\",\n",
    "        \"FV_Age\", \"FV_Gender\", \"FV_Age_Gender\", \n",
    "    ]\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results) \n",
    "    df.columns = colnames\n",
    "\n",
    "    return df, demog_trues\n",
    "\n",
    "def calculate_fairness_AAP(infile, outfile, weighted=False, unionYN=False):\n",
    "\n",
    "  models = [infile]\n",
    "\n",
    "  output, demogs = get_results_AAP(\n",
    "    unionYN,\n",
    "    weighted, \n",
    "    models\n",
    "  )\n",
    "\n",
    "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
    "  wordlists = wordlists.split(\".\")[0]\n",
    "  output[\"model\"] = outfile\n",
    "  output[\"adjustedDI\"] = weighted\n",
    "  output[\"debiasing\"] = debiasing\n",
    "  output[\"wordlists\"] = wordlists\n",
    "  output[\"fullN\"] = unionYN\n",
    "\n",
    "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
    "  demog_df[\"model\"] = outfile\n",
    "  demog_df[\"ratio\"] = weighted\n",
    "\n",
    "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXjevffENJyn",
    "outputId": "a06b2b36-8c1c-4d4a-8a68-f307ff627a7a"
   },
   "outputs": [],
   "source": [
    "\n",
    "taskNames = [\n",
    "            'AskAPatient_AskAPatient'\n",
    "]\n",
    "\n",
    "debiasing = [\n",
    "    \"PT\",\n",
    "    \"PTD\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"Continuous\",\n",
    "    \"Binary\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"BERT\",\n",
    "    \"RoBERTa\"\n",
    "    \"CNN\"\n",
    "]\n",
    "\n",
    "\n",
    "for m in taskNames:\n",
    "    for d in debiasing:\n",
    "        for t in tasks:\n",
    "          for mm in models:\n",
    "            fname = f\"merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
    "            calculate_fairness_AAP(fname, outname, weighted=False, unionYN=False)\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
    "            calculate_fairness_AAP(fname, outname, weighted=True, unionYN=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8CUDxovCLC7"
   },
   "source": [
    "# Hate Speech Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gl6Mo4pKCMbM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generatePlots_HS(basefile, full_N=False, gold_ratio=False):\n",
    "    frames = []\n",
    "\n",
    "    fname = basefile\n",
    "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\") \n",
    "    df = bert_preds\n",
    "\n",
    "    df[\"s1\"] = df[\"sentence\"]\n",
    "    test_data = test_data_HS\n",
    "    test_data[\"s1\"] = test_data[\"text\"]\n",
    "    D = df.merge(test_data, on=\"s1\", how=\"inner\")\n",
    "    D.drop_duplicates(subset=[\"s1\"], inplace=True)\n",
    "    D[\"label\"] = D[\"label_y\"]\n",
    "    print(\"start: \" + str(len(df[\"s1\"])))\n",
    "    print(\"merge: \" + str(len(D[\"s1\"])))\n",
    "\n",
    "    try:\n",
    "      D[\"probs\"] = D[\"preds\"]\n",
    "    except:\n",
    "      try:\n",
    "        D[\"probs\"] = D[\"pred\"]\n",
    "      except:\n",
    "        D[\"probs\"] = D[\"probs\"]\n",
    "\n",
    "    # For continuous, we'll use the stated label\n",
    "    # calculate median and use that as cutoff instead of 0.5 \n",
    "    median_val = 0.5\n",
    "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if float(x[1:-1]) < median_val else 1)\n",
    "    D[\"probs\"] = D[\"probs_binarized\"]\n",
    "    D[\"label_binarized\"] = D[\"label\"]\n",
    "    print(median_val)\n",
    "    D2 = D.dropna()\n",
    "\n",
    "    demogColumns = [\n",
    "                    \"Age_bin\", \"Gender_bin\", \"Race_bin\",\n",
    "        \"Age_Gender\", \"Age_Gender_Race\",\n",
    "        \"Age_Race\", \"Gender_Race\",\n",
    "    ]\n",
    "    DIs = []\n",
    "    FVs = []\n",
    "    demog_trues = []\n",
    "    D2[\"Age_Gender\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int)) / 2\n",
    "    D2[\"Age_Race\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 2\n",
    "    D2[\"Gender_Race\"] = (D2[\"Gender_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 2\n",
    "    D2[\"Age_Gender_Race\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int) + D2[\"Race_bin\"].astype(int)) / 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # laplace smoothing to account for zeros\n",
    "    for dc in demogColumns:\n",
    "      \n",
    "      positive_predictions = D2[\"probs_binarized\"]==1\n",
    "      positive_gold = D2[\"label_binarized\"]==1\n",
    "      protected = D2[dc]==0\n",
    "      privileged = D2[dc] == 1\n",
    "      N = 2\n",
    "      alpha = 1\n",
    "\n",
    "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
    "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
    "\n",
    "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
    "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
    "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
    "\n",
    "      try:\n",
    "        DI = DI_numerator / DI_denominator\n",
    "        ytrue = ytrue_numerator / ytrue_denominator\n",
    "        FV = np.abs(DI_numerator - ypred_global)\n",
    "      except:\n",
    "        DI=0\n",
    "        ytrue=0\n",
    "        FV=0\n",
    "      \n",
    "      if gold_ratio: \n",
    "          DI = DI / ytrue\n",
    "      print(dc)\n",
    "\n",
    "      \n",
    "      DIs.append(DI) \n",
    "      FVs.append(FV)\n",
    "      demog_trues.append((dc, ytrue))\n",
    "\n",
    "    # auc from sklearn\n",
    "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # other metrics: MSE, pearson, F1\n",
    "    mse = 0 \n",
    "    pearsonscore, prob = 0, 0\n",
    "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
    "\n",
    "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
    "\n",
    "\n",
    "\n",
    "def get_results_HS(full_N, gold_ratio, models):\n",
    "    DIs, aucs, xaucs = [], [], []\n",
    "    task = []\n",
    "    dc_tracker = []\n",
    "    l = []\n",
    "    results = []\n",
    "    demog_trues = []\n",
    "\n",
    "    for basefname in models:\n",
    "        outs, dt = generatePlots_HS(basefname, full_N, gold_ratio)\n",
    "        if len(demog_trues) == 0:\n",
    "          demog_trues.extend(dt)\n",
    "        modelname = basefname.split(\"/\")[1]\n",
    "        results.append([modelname, m] + outs)\n",
    "\n",
    "    colnames = [\"model\", \n",
    "              \"DV\", \n",
    "              \"MSE\", \"Pearson R\", \"F1\",\n",
    "              \"AUC\", \n",
    "        \"DI_Age_bin\", \"DI_Gender_bin\", \"DI_Race_bin\",\n",
    "        \"DI_Age_Gender\", \"DI_Age_Gender_Race\",\n",
    "        \"DI_Age_Race\", \"DI_Gender_Race\",\n",
    "        \"FV_Age_bin\", \"FV_Gender_bin\", \"FV_Race_bin\",\n",
    "        \"FV_Age_Gender\", \"FV_Age_Gender_Race\",\n",
    "        \"FV_Age_Race\", \"FV_Gender_Race\",\n",
    "    ]\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results) \n",
    "    df.columns = colnames\n",
    "\n",
    "    return df, demog_trues\n",
    "\n",
    "def calculate_fairness_HS(infile, outfile, weighted=False, unionYN=False):\n",
    "\n",
    "  models = [infile]\n",
    "\n",
    "  output, demogs = get_results_HS(\n",
    "    unionYN,\n",
    "    weighted, \n",
    "    models\n",
    "  )\n",
    "\n",
    "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
    "  wordlists = wordlists.split(\".\")[0]\n",
    "  output[\"model\"] = outfile\n",
    "  output[\"adjustedDI\"] = weighted\n",
    "  output[\"debiasing\"] = debiasing\n",
    "  output[\"wordlists\"] = wordlists\n",
    "  output[\"fullN\"] = unionYN\n",
    "\n",
    "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
    "  demog_df[\"model\"] = outfile\n",
    "  demog_df[\"ratio\"] = weighted\n",
    "\n",
    "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coOK4pEmCQ-L",
    "outputId": "320f8528-2cdc-4635-c44a-be527ffcd967"
   },
   "outputs": [],
   "source": [
    "\n",
    "taskNames = [\n",
    "            'HateSpeech_HateSpeech'\n",
    "]\n",
    "\n",
    "debiasing = [\n",
    "    \"PT\",\n",
    "    \"PTD\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"Continuous\",\n",
    "    \"Binary\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"BERT\",\n",
    "    \"RoBERTa\"\n",
    "    \"CNN\"\n",
    "]\n",
    "\n",
    "\n",
    "for m in taskNames:\n",
    "    for d in debiasing:\n",
    "        for t in tasks:\n",
    "          for mm in models:\n",
    "            fname = f\"merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
    "            calculate_fairness_HS(fname, outname, weighted=False, unionYN=False)\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
    "            calculate_fairness_HS(fname, outname, weighted=True, unionYN=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoM0e8mpbz6G"
   },
   "source": [
    "# MBTI Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLFkZOm4by-V"
   },
   "outputs": [],
   "source": [
    "def generatePlots_MBTI(basefile, full_N=False, gold_ratio=False):\n",
    "    frames = []\n",
    "\n",
    "    fname = basefile\n",
    "    bert_preds = pd.read_csv(fname, quotechar=\"\\\"\", encoding=\"utf-8\") \n",
    "    df = bert_preds\n",
    "\n",
    "    df[\"s1\"] = df[\"sentence\"]\n",
    "    D = df\n",
    "    if \"CNN\" in fname:\n",
    "      bertfile = fname.replace(\"CNN\", \"BERT\")\n",
    "      test_data = pd.read_csv(bertfile, quotechar=\"\\\"\", encoding=\"utf-8\")\n",
    "      D = df.merge(test_data, on=\"sentence\", how=\"inner\")\n",
    "      D[\"label\"] = D[\"label_y\"]\n",
    "      print(\"start: \" + str(len(df[\"s1\"])))\n",
    "      print(\"merge: \" + str(len(D[\"s1\"])))\n",
    "    else:\n",
    "      try:\n",
    "        D[\"probs\"] = D[\"preds\"]\n",
    "      except:\n",
    "        D[\"probs\"] = D[\"pred\"]\n",
    "\n",
    "    # For continuous, we'll use the stated label\n",
    "    # calculate median and use that as cutoff instead of 0.5 \n",
    "    median_val = 0.5\n",
    "    D[\"probs\"] = D[\"probs\"].apply(lambda x: float(x[1:-1]))\n",
    "    D[\"probs_binarized\"] = D[\"probs\"].apply(lambda x: 0 if x < median_val else 1)\n",
    "    D[\"label_binarized\"] = D[\"label\"]\n",
    "    print(median_val)\n",
    "    D2 = D.dropna()\n",
    "\n",
    "    demogColumns = [\n",
    "        \"Age_bin\", \"Gender_bin\", \n",
    "        \"Age_Gender\"\n",
    "    ]\n",
    "    DIs = []\n",
    "    FVs = []\n",
    "    demog_trues = []\n",
    "    D2[\"Gender_bin\"] = (D2[\"x1\"] == \"m\").astype(int)\n",
    "    D2[\"Age_bin\"] = (D2[\"x2\"] < 55).astype(int)\n",
    "    D2[\"Age_Gender\"] = (D2[\"Age_bin\"].astype(int) + D2[\"Gender_bin\"].astype(int)) / 2\n",
    "\n",
    "    # laplace smoothing to account for zeros\n",
    "    for dc in demogColumns:\n",
    "      \n",
    "      positive_predictions = D2[\"probs_binarized\"]==1\n",
    "      positive_gold = D2[\"label_binarized\"]==1\n",
    "      protected = D2[dc]==0\n",
    "      privileged = D2[dc] == 1\n",
    "      N = 2\n",
    "      alpha = 1\n",
    "\n",
    "      DI_numerator = (sum(positive_predictions & protected) + alpha) / (sum(protected) + N)\n",
    "      DI_denominator =  (sum(positive_predictions & privileged) + alpha) / (sum(privileged) + N)\n",
    "\n",
    "      ytrue_numerator = (sum(positive_gold & protected) + alpha) / (sum(protected) + N)\n",
    "      ytrue_denominator =  (sum(positive_gold & privileged) + alpha) / (sum(privileged) + N)\n",
    "      ypred_global = (sum(positive_predictions) + alpha) / (len(D2[dc]) + N)\n",
    "\n",
    "      try:\n",
    "        DI = DI_numerator / DI_denominator\n",
    "        ytrue = ytrue_numerator / ytrue_denominator\n",
    "        FV = np.abs(DI_numerator - ypred_global)\n",
    "      except:\n",
    "        DI=0\n",
    "        ytrue=0\n",
    "        FV=0\n",
    "      \n",
    "      if gold_ratio: \n",
    "          DI = DI / ytrue\n",
    "      print(dc)\n",
    "\n",
    "      \n",
    "      DIs.append(DI) \n",
    "      FVs.append(FV)\n",
    "      demog_trues.append((dc, ytrue))\n",
    "\n",
    "    # auc from sklearn\n",
    "    fpr, tpr, _ = metrics.roc_curve(D2[\"label_binarized\"], D2[\"probs\"], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # other metrics: MSE, pearson, F1\n",
    "    mse = 0 \n",
    "    pearsonscore, prob = 0, 0\n",
    "    f1score = f1_score(D2[\"label_binarized\"], D2[\"probs_binarized\"])\n",
    "\n",
    "    return [mse, pearsonscore, f1score, auc] + DIs + FVs, demog_trues\n",
    "\n",
    "\n",
    "\n",
    "def get_results_MBTI(full_N, gold_ratio, models):\n",
    "    DIs, aucs, xaucs = [], [], []\n",
    "    task = []\n",
    "    dc_tracker = []\n",
    "    l = []\n",
    "    results = []\n",
    "    demog_trues = []\n",
    "\n",
    "    for basefname in models:\n",
    "        outs, dt = generatePlots_MBTI(basefname, full_N, gold_ratio)\n",
    "        if len(demog_trues) == 0:\n",
    "          demog_trues.extend(dt)\n",
    "        modelname = basefname.split(\"/\")[1]\n",
    "        results.append([modelname, m] + outs)\n",
    "\n",
    "    colnames = [\"model\", \n",
    "              \"DV\", \n",
    "              \"MSE\", \"Pearson R\", \"F1\",\n",
    "              \"AUC\", \n",
    "        \"DI_Age_bin\", \"DI_Gender_bin\", \n",
    "        \"DI_Age_Gender\", \n",
    "        \"FV_Age_bin\", \"FV_Gender_bin\",\n",
    "        \"FV_Age_Gender\", \n",
    "    ]\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results) \n",
    "    df.columns = colnames\n",
    "\n",
    "    return df, demog_trues\n",
    "\n",
    "def calculate_fairness_MBTI(infile, outfile, weighted=False, unionYN=False):\n",
    "\n",
    "  models = [infile]\n",
    "\n",
    "  output, demogs = get_results_MBTI(\n",
    "    unionYN,\n",
    "    weighted, \n",
    "    models\n",
    "  )\n",
    "\n",
    "  debiasing, wordlists = outfile.split(\"_\")[:2]\n",
    "  wordlists = wordlists.split(\".\")[0]\n",
    "  output[\"model\"] = outfile\n",
    "  output[\"adjustedDI\"] = weighted\n",
    "  output[\"debiasing\"] = debiasing\n",
    "  output[\"wordlists\"] = wordlists\n",
    "  output[\"fullN\"] = unionYN\n",
    "\n",
    "  output.to_csv(f\"fairness_output_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n",
    "  demog_df = pd.DataFrame(demogs, columns=[\"Demographic\", \"Y1_Ratio\"])\n",
    "  demog_df[\"model\"] = outfile\n",
    "  demog_df[\"ratio\"] = weighted\n",
    "\n",
    "  demog_df.to_csv(f\"y1_ratio_{outfile}_fullN_{unionYN}_goldRatio_{weighted}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzpfZKsLeDzq",
    "outputId": "59e12f80-ff92-4145-abbf-0cf6ece198c3"
   },
   "outputs": [],
   "source": [
    "taskNames = [\n",
    "            'MBTI_perceiving',\n",
    "             'MBTI_thinking',\n",
    "]\n",
    "\n",
    "debiasing = [\n",
    "    \"PT\",\n",
    "    \"PTD\"\n",
    "]\n",
    "\n",
    "tasks = [\n",
    "    \"Continuous\",\n",
    "    \"Binary\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    \"BERT\",\n",
    "    \"RoBERTa\"\n",
    "    \"CNN\"\n",
    "]\n",
    "\n",
    "\n",
    "for m in taskNames:\n",
    "    for d in debiasing:\n",
    "        for t in tasks:\n",
    "          for mm in models:\n",
    "            fname = f\"merged/{m}_{t}_{d}_{mm}_test.csv\"\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_F_F_test.csv\"\n",
    "            calculate_fairness_MBTI(fname, outname, weighted=False, unionYN=False)\n",
    "            outname = f\"{m}_{t}_{d}_{mm}_T_F_test.csv\"\n",
    "            calculate_fairness_MBTI(fname, outname, weighted=True, unionYN=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5aM0or61JgI"
   },
   "outputs": [],
   "source": [
    "# concatenate everything together\n",
    "!head -n 1 fairness_output_FIPI_Agreeable_Continuous_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_Psych_FIPI.csv\n",
    "!head -n 1 fairness_output_Hatespeech_Hatespeech_Binary_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_HS.csv\n",
    "!head -n 1 fairness_output_AskAPatient_AskAPatient_Continuous_PT_BERT_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_AAP.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq9NsWLuja1w"
   },
   "outputs": [],
   "source": [
    "!head -n 1 fairness_output_MBTI_perceiving_Binary_PT_CNN_F_F_test.csv_fullN_False_goldRatio_False.csv > results_bert_acl22_MBTI.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGMVaPgR2rLK",
    "outputId": "15c3541e-17bd-4732-c7ab-d9266c351f59"
   },
   "outputs": [],
   "source": [
    "!head results_bert_acl22*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Y57gD072tgH"
   },
   "outputs": [],
   "source": [
    "!tail -n 1 -q fairness_output_FIPI* >> results_bert_acl22_Psych_FIPI.csv\n",
    "!tail -n 1 -q fairness_output_Psych* >> results_bert_acl22_Psych_FIPI.csv\n",
    "!tail -n 1 -q fairness_output_Ha* >> results_bert_acl22_HS.csv\n",
    "!tail -n 1 -q fairness_output_Ask* >> results_bert_acl22_AAP.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwsLk4I8jfo0"
   },
   "outputs": [],
   "source": [
    "!tail -n 1 -q fairness_output_MBTI* >> results_bert_acl22_MBTI.csv"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ACL2022_fairness_metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
